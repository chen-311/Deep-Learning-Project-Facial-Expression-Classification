{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load package\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# fer2013 dataset:\n",
    "# Training       28709\n",
    "# PrivateTest     3589\n",
    "# PublicTest      3589\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion labels from FER2013:\n",
    "emotion = {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3,\n",
    "           'Sad': 4, 'Surprise': 5, 'Neutral': 6}\n",
    "emo     = ['Angry', 'Fear', 'Happy',\n",
    "           'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filepath = 'fer2013.csv'\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 3)\n",
      "       emotion                                             pixels        Usage\n",
      "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
      "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
      "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
      "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
      "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
      "Training       28709\n",
      "PublicTest      3589\n",
      "PrivateTest     3589\n",
      "Name: Usage, dtype: int64\n",
      "(28709, 3)\n",
      "(3589, 3)\n"
     ]
    }
   ],
   "source": [
    "#explore data\n",
    "print (df.shape)\n",
    "print (df.tail())\n",
    "print (df.Usage.value_counts())\n",
    "#split the train and test from the whole dataset.\n",
    "df_train = df[df.Usage == 'Training']\n",
    "print (df_train.shape)\n",
    "df_test = df[df.Usage == 'PublicTest']\n",
    "print (df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35340, 3)\n",
      "       emotion                                             pixels        Usage\n",
      "35866        6  87 82 59 61 72 102 143 130 90 95 143 173 146 1...  PrivateTest\n",
      "35871        6  112 102 98 89 98 133 164 185 180 179 185 169 1...  PrivateTest\n",
      "35876        6  29 29 27 31 49 56 29 19 22 20 34 43 55 71 85 9...  PrivateTest\n",
      "35877        6  139 143 145 154 159 168 176 181 190 191 195 19...  PrivateTest\n",
      "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
      "Training       28273\n",
      "PrivateTest     3534\n",
      "PublicTest      3533\n",
      "Name: Usage, dtype: int64\n",
      "3    8989\n",
      "6    6198\n",
      "4    6077\n",
      "2    5121\n",
      "0    4953\n",
      "5    4002\n",
      "Name: emotion, dtype: int64\n",
      "706\n",
      "       emotion                                             pixels        Usage\n",
      "23631        2  255 251 149 114 113 101 112 112 119 134 143 14...     Training\n",
      "34247        4  95 37 5 0 26 141 180 185 183 179 168 128 96 95...  PrivateTest\n",
      "20517        6  214 215 236 251 255 255 255 255 254 255 200 14...     Training\n",
      "102          6  58 108 121 128 165 166 189 192 204 196 181 180...     Training\n",
      "20131        3  1 1 3 14 37 54 68 82 88 94 102 109 118 121 123...     Training\n",
      "3    184\n",
      "4    119\n",
      "6    110\n",
      "2    107\n",
      "0    103\n",
      "5     83\n",
      "Name: emotion, dtype: int64\n",
      "Training       573\n",
      "PrivateTest     72\n",
      "PublicTest      61\n",
      "Name: Usage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#split the sample\n",
    "sample_split=0.02\n",
    "frames = []\n",
    "classes=['Angry', 'Fear', 'Happy',\n",
    "           'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "for _class in classes:\n",
    "    class_df = df[df['emotion'] == emotion[_class]]\n",
    "    frames.append(class_df)\n",
    "data = pd.concat(frames, axis=0)\n",
    "print (data.shape)\n",
    "print (data.tail())\n",
    "print (data.Usage.value_counts())\n",
    "print (data.emotion.value_counts())\n",
    "\n",
    "rows = random.sample(list(data.index), int(len(data)*sample_split))\n",
    "print (len(rows))\n",
    "data1 = data.loc[rows]\n",
    "print (data1.tail())\n",
    "print (data1.emotion.value_counts())\n",
    "print (data1.Usage.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573, 2304)\n",
      "(573,)\n",
      "(61, 2304)\n",
      "(61,)\n",
      "(573,)\n"
     ]
    }
   ],
   "source": [
    "#reconstruct data pixels, from string to int\n",
    "\n",
    "data_train = data1[data1.Usage == 'Training']\n",
    "data_test = data1[data1.Usage == 'PublicTest']\n",
    "\n",
    "#reconstruct train x and y\n",
    "data_train_x = list(data_train[\"pixels\"])\n",
    "data_train_y = list(data_train[\"emotion\"])\n",
    "\n",
    "train_x = []\n",
    "for i in range(len(data_train_x)):\n",
    "    each_pixel = [int(num) for num in data_train_x[i].split()]\n",
    "    train_x.append(each_pixel)\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(data_train_y )\n",
    "\n",
    "\n",
    "print (train_x.shape)\n",
    "print (train_y.shape)\n",
    "\n",
    "\n",
    "#reconstruct test x and y\n",
    "data_test_x = list(data_test[\"pixels\"])\n",
    "data_test_y = list(data_test[\"emotion\"])\n",
    "\n",
    "test_x = []\n",
    "for i in range(len(data_test_x)):\n",
    "    each_pixel = [int(num) for num in data_test_x[i].split()]\n",
    "    test_x.append(each_pixel)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(data_test_y )\n",
    "\n",
    "\n",
    "print (test_x.shape)\n",
    "print (test_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# to categorical\n",
    "\n",
    "print (train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (573, 48, 48, 1)\n",
      "573 train samples\n",
      "61 test samples\n",
      "(573, 7)\n"
     ]
    }
   ],
   "source": [
    "#train CNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 7\n",
    "nb_epoch = 16\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 48, 48\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "X_train = train_x\n",
    "X_test = test_x\n",
    "Y_train = train_y\n",
    "Y_test = test_y\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],  img_rows, img_cols,1)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)\n",
    "\n",
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 1, 1, 32)          73760     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 94,247\n",
      "Trainable params: 94,247\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(nb_filters, (img_rows, img_cols), activation='relu',\n",
    "                        input_shape=( img_rows, img_cols,1)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "573/573 [==============================] - 1s 943us/step - loss: 1.9172 - acc: 0.2373\n",
      "Epoch 2/16\n",
      "573/573 [==============================] - 0s 49us/step - loss: 1.8716 - acc: 0.2496\n",
      "Epoch 3/16\n",
      "573/573 [==============================] - 0s 51us/step - loss: 1.8461 - acc: 0.2496\n",
      "Epoch 4/16\n",
      "573/573 [==============================] - 0s 49us/step - loss: 1.8311 - acc: 0.2496\n",
      "Epoch 5/16\n",
      "573/573 [==============================] - 0s 49us/step - loss: 1.8192 - acc: 0.2496\n",
      "Epoch 6/16\n",
      "573/573 [==============================] - 0s 46us/step - loss: 1.8072 - acc: 0.2496\n",
      "Epoch 7/16\n",
      "573/573 [==============================] - 0s 49us/step - loss: 1.8005 - acc: 0.2496\n",
      "Epoch 8/16\n",
      "573/573 [==============================] - 0s 59us/step - loss: 1.7917 - acc: 0.2496\n",
      "Epoch 9/16\n",
      "573/573 [==============================] - 0s 51us/step - loss: 1.7869 - acc: 0.2496\n",
      "Epoch 10/16\n",
      "573/573 [==============================] - 0s 49us/step - loss: 1.7803 - acc: 0.2496\n",
      "Epoch 11/16\n",
      "573/573 [==============================] - 0s 49us/step - loss: 1.7788 - acc: 0.2496\n",
      "Epoch 12/16\n",
      "573/573 [==============================] - 0s 50us/step - loss: 1.7709 - acc: 0.2496\n",
      "Epoch 13/16\n",
      "573/573 [==============================] - 0s 69us/step - loss: 1.7671 - acc: 0.2496\n",
      "Epoch 14/16\n",
      "573/573 [==============================] - 0s 67us/step - loss: 1.7612 - acc: 0.2496\n",
      "Epoch 15/16\n",
      "573/573 [==============================] - 0s 68us/step - loss: 1.7627 - acc: 0.2496\n",
      "Epoch 16/16\n",
      "573/573 [==============================] - 0s 65us/step - loss: 1.7562 - acc: 0.2496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7987fe81d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch)\n",
    "#score = model.evaluate(X_test, Y_test)\n",
    "#print('Test score:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then try RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
